\documentclass[11pt]{article}
\usepackage{graphicx}
\usepackage{float}
\restylefloat{table}
\usepackage{subcaption}
\renewcommand\thesubfigure{\roman{subfigure}}
\usepackage[a4paper, total={6in, 8in}]{geometry}


\title{Linear Models, Assessed Practical}
\author{Practical No. P049}
\begin{document}

\maketitle
\newpage
\section{Summary}

\section{Induction}
Motor learning and Hand-eye coordination are affected by multiple factors,the United States Nava Postgraduate School invited 108 people to their lab for discovering what affects Motor learning and hand-eye coordination.The experiment used a rotating disk with a 3/4-inch target spot, the subject needs to contact the target spot with a metal wand, and the total contact time during the 15 seconds was recorded, as well as number of trails, shape of tracker,age and sex of subject were recorded. We are interested in investigating the association between contact time with age, sex and shape. In this paper we apply normal linear model on those variables to find a proper model that can explain the relation between each variables with contact time, and how these variables explain the way subjects improve across trials. Before we fit the models, we explore and analysis data, which helps us to understand the relation between variables and build the best model. Based AIC(Akaike information criterion) and the information we find in data, we select the best model from all the possible models. Finally we explain what find we in the model, and answer the two question that We give previous, 

\section{Methods}
Firstly, Box plots, histograms and scatter plots are used to give a basic exploration of the contact time with other variables Linear models are the model that we used to fit our data, we only consider normal linear models with fixed effects. Forward stepwise based on AIC is used to select the best model based on minimizing AIC score, we use this method to automatic select proper model for us, but we still need human judgement for the results that stepwise gives us. Boxcox is used to find if the data need transformation and find a simple transformation that leads to normality. Diagnostic plots are used to check the data follow the assumptions and outliers analysis. T test and F test are used to check the significance of models and parameters in models.

\section{Results}
\subsection{Data exploration}
\begin{figure}[H]
<<echo=FALSE>>=
tracking = read.table("P:/R Data/tracking.txt", header = T)
plot(tracking)
@
  \caption{\textbf{Pairwies plots: }{plot pairwise combinations of variables in scatterplots.}}
\end{figure}

\begin{table}[H]
\centering
\begin{tabular}{rrrrr}
  \hline
 & Trial1 & Trial2 & Trial3 & Trial4 \\ 
  \hline
Trial1 & 1.00 & 0.91 & 0.90 & 0.89 \\ 
  Trial2 & 0.91 & 1.00 & 0.92 & 0.93 \\ 
  Trial3 & 0.90 & 0.92 & 1.00 & 0.94 \\ 
  Trial4 & 0.89 & 0.93 & 0.94 & 1.00 \\ 
   \hline
   \caption{\textbf{Correlation table: }{correlation matrix of trails}}
\end{tabular}
\end{table}

By looking at summaries(table 1) and exploratory plots(figure 1), we find the plot between each trials are highly correlated with each other, we decide to come all trails as one variable by using long form. The long form is one row per observation, rather than one row per 5 observations: the new data frame with columns sex, age, trial and time. The trial variable takes values 1, 2, 3, 4, indicating the trial number. The time gives the time measured in the given trial.

\begin{figure}[H]

\begin{minipage}[b]{.5\linewidth}
\centering%
<<echo=FALSE>>=
tracking = read.table("P:/R Data/tracklong.txt", header = T)

plot(time[sex == "M"] ~ age[sex == "M"], data = tracking, pch = 16,
     ylab = "Time measured in trial (seconds)", xlab = "Age (years)")
points(time[sex == "F"] ~ age[sex == "F"], data = tracking, pch = 16, col = 2)
abline(v = 20, lty = 2)
legend("topright", col = c(2, 1), pch = 16, legend = c("female", "male"))
@
\subcaption{Q-Q plot for value of time}
\end{minipage}
\hfill%
\begin{minipage}[b]{.5\linewidth}
\centering%
<<echo=FALSE>>=
plot(time[shape == "Box"] ~ age[shape == "Box"], data = tracking, pch = 16,
     ylab = "Time measured in trial (seconds)", xlab = "Age (years)")
points(time[shape == "Circle"] ~ age[shape == "Circle"], data = tracking, pch = 16, col = 2)
abline(v = 20, lty = 2)
legend("topright", col = c(2, 1), pch = 16, legend = c("Circle", "Box"))
@
\subcaption{Q-Q plot for $\sqrt{time}$}
\end{minipage}
\caption{Q-Q plot for checking time variable}
\end{figure}

\begin{figure}[H]
\centering
  \caption{\textbf{Scatter plot between times and age:} \emph{Left: }{This plot is scatter plot for times and age, we add sex as a factor, which indicate by color, and the vertical line is at age 20. }\emph{Right: }{change the factor to shape.}}
\end{figure}

From figure 2, we can see there is a big gap between age, so we add a vertical line at age 20 on plot, it separates the plot into two parts. If we look at the left part, the contact time increases as age increases. For the right side, the contact time decreases as age decrease. From the left plot, it indicates more male are older than 20, and male's performance has higher variation then female. From the right plot, at same age, Box gives higher performance than circle We will consider age, and shape are potential variables in our model.

\begin{figure}[H]
\centering
<<echo=FALSE, out.width='4in'>>=
par(mar = c(5, 6, 3, 3) + 0.1)
boxplot(time ~ trial + sex + shape, data = tracking,
        horizontal = TRUE, xlim = c(0, 17), ylim = c(0, 12), las = 1,
        xlab = "Value of time")
@
\end{figure}

\begin{figure}[H]
\centering
<<echo=FALSE, out.width='4in'>>=
par(mfrow=c(2,2))
boxplot(time ~ trial, data = tracking, ylim = c(0, 12), las = 1,xlab = "Trials", ylab = "Time (seconds)")
boxplot(time ~ sex, data = tracking, ylim = c(0, 12), las = 1,xlab = "Sex(F: Female, M: Male)",ylab = "Time (seconds)")
boxplot(time ~ shape, data = tracking, ylim = c(0, 12), las = 1,xlab = "Shape",ylab = "Time (seconds)")
@
  \caption{\textbf{Box plot of all categorical variables respect to time: } \emph{Top:}{ On the y aixs 1,2,3,4 represent the different trials, M, F represent male and female, Box, Circle represent different shapes. For example, the top label on the y aixs, 4.M.Circle, means the contact time for a male who did his fourth trail on a circle shape. }\emph{Middle left:}{ Box plot of Time and Trails. }\emph{Middle right:}{ Box plot of Time and Sex. }\emph{Bottom:}{ Box plot of Shapes.}}
\end{figure}

We first draw the top plot in figure 3, put all categorical variables together, we can see the mean values and the variances for different groups are different, so some variables affect the time, in order to make the affect easier to see, we draw the categorical variables with time separately, which are middle left, middle right and bottom plots in figure 3. From Middle left plot, it gives us an increasing trend across trails, the more trails subjects did, the better result they got. From the middle right, we can see that male has a better results than female, but the male has a high variance compares to female. But from bottom plot, means of two groups don't look significantly different, but affects the variance, we can see the Circle has bigger variance than Box. 


\subsection{Modelling data}
<<echo=FALSE>>=
library(MASS)
model1 = lm(time ~ sex + age + trial, data = tracking)
# stp = stepAIC(model1, 
#               scope = list(upper = ~sex * age * trial * shape,lower = ~1))
model2 = lm(formula = time ~ sex + age + trial + shape + sex:age + age:trial + age:shape, 
           data = tracking)
@

Based on what we get from Data exploration part, we decide our initial model to be "time ~ sex + age + trial", and names it as model1 we put it into "stepAIC" function, the stepAIC returns us "time ~ sex + age + trial + shape + age:shape + sex:age + age:trial" as the best model with AIC equal to 492.87. Now we update our model to the model that stepAIC gives us, and names it as model2.

<<echo=FALSE>>=
# summary(model2)
@
\begin{table}[H]
\centering
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\ 
  \hline
(Intercept) & 1.9120 & 0.4350 & 4.40 & 0.0000 \\ 
  sexM & -0.2503 & 0.3078 & -0.81 & 0.4167 \\ 
  age & -0.0084 & 0.0171 & -0.49 & 0.6223 \\ 
  trial & 0.1076 & 0.1360 & 0.79 & 0.4293 \\ 
  shapeCircle & -1.1749 & 0.3101 & -3.79 & 0.0002 \\ 
  sexM:age & 0.0550 & 0.0123 & 4.48 & 0.0000 \\ 
  age:trial & 0.0117 & 0.0052 & 2.23 & 0.0261 \\ 
  age:shapeCircle & 0.1220 & 0.0125 & 9.74 & 0.0000 \\ 
   \hline
   \caption{\textbf{Summary table of model2}}
\end{tabular}
\end{table}

R does F-test for the model, the null hypothesis for F-test is the model is not significant, the alternative is the model is significant.R gives p-value of F-test equal to 2.210-16, which is less than 0.01, so the model is significant at 0.01 alpha level. But if we look at the T-test for the parameters, which tests if the parameters are significant, there are three variables(sex, age, trails) are not significant at 0.01 significant level. But only if the model doesn't have interaction parts, the interpretation of the hypothesis test of single  variables do not change, since we have interaction between age and sex, age and trial, age and shape, so the hypothesis tests for sex, age, and trial might not be useful. So we keep this model as our best model for right now.

\begin{figure}[H]
\centering
<<echo=FALSE, out.width='4in'>>=
par(mfrow=c(1,1))
boxcox(model2,lambda = seq(0, 1, length = 10))
@
  \caption{\textbf{Boxcox plot:} {Boxcox plot of the model2}}
\end{figure}

The result from boxcox indicates that the 95\% confident interval for $\lambda$ is around 0.5 to 0.7. we need to transfer the time to the power of the $\lambda$, here we choose $\lambda$ to be 0.5, which is the square root of the time.

We look at the Q-Q plot for time before and after transformation
\begin{figure}[H]

\begin{minipage}[b]{.5\linewidth}
\centering%
<<echo=FALSE>>=
qqnorm(tracking$time)
lines(x=c(-3,3), y = c(0,12))
@
\subcaption{Q-Q plot for value of time}
\end{minipage}
\hfill%
\begin{minipage}[b]{.5\linewidth}
\centering%
<<echo=FALSE>>=
qqnorm(sqrt(tracking$time))
lines(x=c(-3,3), y = c(0,3.5))
@
\subcaption{Q-Q plot for $\sqrt{time}$}
\end{minipage}
\caption{Q-Q plot for checking time variable}
\end{figure}

In the Q-Q plot, the most of the points are on the gray line. We consider the errors to follow a normal distribution. We can see the right plot has more data on the gray line than left plot, we can see that after the transformation, the time varible is more normal.

<<echo=FALSE>>=
new_tracking = tracking
new_tracking$time = (new_tracking$time)^(0.5)
model2 = lm(formula = time ~ sex + age + trial + shape + sex:age + age:trial + age:shape, 
           data = new_tracking)
stp = stepAIC(model2,
              scope = list(upper = ~sex * age * trial * shape,lower = ~1))

model3 = lm(formula = time ~ sex + age + trial + shape + sex:age + age:shape,
           data = new_tracking)
@
After we do the boxcox variable transformation, we refit the data, and do the stepAIC again. This time, the stepAIC gives us"time ~ sex + age + trial + shape + sex:age + age:trial + age:shape + sex:shape" as the best model, so we update our model to this one and names it as model3. 

<<echo=FALSE>>=
# summary(model3)
@
\begin{table}[ht]
\centering
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\ 
  \hline
(Intercept) & 1.1113 & 0.0970 & 11.45 & 0.0000 \\ 
  sexM & -0.0523 & 0.0904 & -0.58 & 0.5629 \\ 
  age & 0.0089 & 0.0032 & 2.77 & 0.0058 \\ 
  trial & 0.0948 & 0.0222 & 4.28 & 0.0000 \\ 
  shapeCircle & -0.3122 & 0.0911 & -3.43 & 0.0007 \\ 
  sexM:age & 0.0132 & 0.0036 & 3.66 & 0.0003 \\ 
  age:shapeCircle & 0.0292 & 0.0037 & 7.94 & 0.0000 \\ 
   \hline
   \caption{\textbf{Summary table of model3}}
\end{tabular}
\end{table}

\begin{figure}[H]
\centering
<<echo=FALSE>>=
par(mfrow=c(2,2))
plot(model3)
@
  \caption{\textbf{Diagnostic plots: } \emph{Top right:}{ Residual plot. }\emph{Top left: }{ Q-Q plot. }\emph{Bottom left: }{ Standardised residual plot. }\emph{Bottom right: }{Leverage plot.}}
\end{figure}

The upper left plot shows the residuals versus the fitted values. If the variance is constant for data, all the points fall randomly on the two side of red horizontal line, but here, the more points have positive residuals when fitted values around 1.5 to 2.5, but we don't see any pattern in the plot, so we think data don't valid assumption of equal variance
The upper right plot is a Q-Qnorm plot of the residuals. This plot evaluates the least-squares regression assumption that the errors are normally distributed. Here, the most of the points are on the gray line. We consider the errors to follow a normal distribution. 
The lower left plot is a scale-location plot. The regression assumes homoscedasticity, that the variance in the residuals doesn'tâ€™t change as a function of x. If that assumption is correct, then the red line should be relatively flat, the red line is flat here. This shows that the errors are homoscedasticity.
The lower right plot shows the standardized residuals against leverage. Leverage is a measure of how much each data point influences the regression. Here, we can see that R automatically marked the outliers, but they are still in the cook's distance, and also look at Q-Q plot, there are no points obviously far away from diagonal, so we don't treat them as outlier.

\subsection{Data transformation}
As we find in Data exploration section, the age data has a gap around age 20, so we split the age into two groups that are greater than 20, and less than 20. We do a box plot to see if this factor will affect the time.
\begin{figure}[H]
\centering
<<echo=FALSE, out.width='4in'>>=
new_tracking$grp <- factor(ifelse(new_tracking$age < 20, "young", "old"),
                      levels = c("young", "old"))

plot(new_tracking$grp,new_tracking$time, ylab = "Time measured in trial (seconds)", xlab = "Age group")
@
  \caption{\textbf{Box plot:} {Boxcox plot of subject younger than 20 and others}}
\end{figure}
From the box plot, we can see that age group has a significant on time, the old group performs better than the young group. So we will consider to put this variable into our model


<<echo=FALSE>>=
# model3 = lm(formula = time ~ sex + age + trial + shape + grp + sex:age + age:shape,
#            data = new_tracking)
# stp = stepAIC(model3,
#               scope = list(upper = ~sex * age * trial * shape * grp,lower = ~1))
# model4 = lm(formula = time~ sex + age + trial + shape + grp + sex:age + age:shape + 
#     age:grp + shape:grp + age:trial, data = new_tracking)
@

Another variable that we need consider to do transformation is \textbf{Trails}. The \textbf{Trails} can be treated either as numeric or category, we need to specify how the different types will affect our model. If we treat \textbf{Trails} as numerical data, then the different trails will be marked as 1,2,3,4. If we fit it into model, we will get $\beta_{trails}\cdot Trails$ term, and \textbf{Trials} can be 1 to 4. That means, if the subject does the experiment again, he/she will increase the contant time by $\beta_{trails}$. But we don't think that is true, because the more experiment that subject does, the less contact time that subject can improve. We believe if we treat trails as a categorical data is more proper in this case. we make trail as factor and add age factor into data. 

<<echo=FALSE>>=
new_tracking$trial = factor(new_tracking$trial)
model3 = lm(formula = time ~ sex + age + trial + shape + grp + sex:age + age:shape,
           data = new_tracking)
stp = stepAIC(model3,
              scope = list(upper = ~sex * age * trial * shape * grp,lower = ~1))
model5 = lm(formula = time ~ sex + age + trial + shape + grp + sex:age + age:shape +
    age:grp + shape:grp, data = new_tracking)
@
we use new data to do StepAIC again, it gives "time ~ sex + age + trial + shape + grp + sex:age + age:shape + age:grp + shape:grp" as best model. 

<<echo=FALSE>>=
# summary(model5)
@

\begin{table}[ht]
\centering
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\ 
  \hline
(Intercept) & 0.0254 & 0.1137 & 0.22 & 0.8231 \\ 
  sexM & -0.1422 & 0.0663 & -2.14 & 0.0326 \\ 
  age & 0.1201 & 0.0098 & 12.30 & 0.0000 \\ 
  trial2 & 0.1574 & 0.0513 & 3.07 & 0.0023 \\ 
  trial3 & 0.2312 & 0.0513 & 4.51 & 0.0000 \\ 
  trial4 & 0.2913 & 0.0513 & 5.68 & 0.0000 \\ 
  shapeCircle & -0.2489 & 0.0910 & -2.73 & 0.0065 \\ 
  grpold & 3.5755 & 0.1925 & 18.58 & 0.0000 \\ 
  sexM:age & 0.0146 & 0.0026 & 5.52 & 0.0000 \\ 
  age:shapeCircle & 0.0516 & 0.0082 & 6.30 & 0.0000 \\ 
  age:grpold & -0.1743 & 0.0101 & -17.25 & 0.0000 \\ 
  shapeCircle:grpold & -0.9847 & 0.2369 & -4.16 & 0.0000 \\ 
   \hline
   \caption{\textbf{Summary table for model5}}
\end{tabular}
\end{table}
The Table 4 shows us the p-value of all variables are less than 0.05 except intercept, we can say that all the variables are significant at 0.05 significant level. 

\subsection{Interpret model}
Now we are going through each variable in the model5 to explore the relation between time and those variables. The first term is \textbf{sexM} = -0.1422, which means if the subject is male, he will get 0.1422 $\sqrt{time}$ less than female, but from the box plot of sex respect to time, we see that male overall performances are better than female, so we look our model5 again, we notice there is an interaction term \textbf{sexM:age}, which is 0.0146. It means if the subject is male, the older he is, the better he could do. If we look at the figure 2 left plot, and the subjects under 20 years old, the female has same performance as male, even a little bit better than male. If we combine the \textbf{sexM} and \textbf{sexM:age} together, we will get a conclusion for sex variable, the older male can do better than female. 

The next term is age, from the experience of interpreting sex variable, this time we interpreting terms that involve age, instead of interpreting age term only. In the model we have \textbf{age}=0.1201,\textbf{sexM:age}=0.0146,\textbf{age:shapeCircle}=0.0516,\textbf{age:grpold}=-0.1743. The \textbf{age} term is positive, which means the older people can do better than younger people, if we look at the Figure 2, we can see that is not true, Figure 2 shows after around 40 years old, people start performing worse, but the textbf{age:grpold} is negative, which soluve this problem. The difference between \textbf{sexM:age} and \textbf{age:grpold} is 0.1201-0.1743=-0.0542, it tells us the for the subjects in older group, the order they are, the worst they can do in the experiments. The relation between age and time is the adult can do better than young and old people. For \textbf{sexM:age}, we have already interpreted it, for \textbf{age:shapeCircle}, we will talk about it with \textbf{shapeCircle} later. 

Next we will talk about trail variable, we have \textbf{trial2}=0.1574, \textbf{trial3}=0.2312 and \textbf{trial4}=0.2913. If trail is 1, trail won't contribute anything to contact time, which means the model set trail1 as base line, if the trail is 2, it will increase $\sqrt{time}$ for 0.1574, if the trail is 3, it will increase $\sqrt{time}$ for 0.2312, 0.2913 for trail4. From trail1 to trail2, the $\sqrt{time}$ increases 0.1574, but from trail2 to trail3, the $\sqrt{time}$ increases 0.2312-0.1574=0.0738, which is less than the difference between trail1 and trail2. For trail3 to trail4, the difference is 0.2913-0.2312 = 0.0601, it is also less than the difference between trail2 and trail3. It perfect match what we talked about at section Data transformation, which is "the more experiment that subject does, the less contact time that subject can improve".

The last variable is shape. The \textbf{shapeCircle}=-0.2489, \textbf{age:shapeCircle}=0.0516, and \textbf{shapeCircle:grpold}=-0.9847. From Figure 2 right plot, we can see that subjucts have better performance on Box shape, because the there are more red dots have higher contact time, so it makes sense that \textbf{shapeCircle} is negative, which means circle shape will reduce subject's performance. If we look at the right plot in figure 2 again, subjects under 20 years old, the contact time in circle shape increases as age increases, so we have term \textbf{age:shapeCircle} is positive. But this relation is not hold for subject who is older than 20, the \textbf{shapeCircle:grpold} term capture this situation, \textbf{shapeCircle:grpold} is negative value, it cancels some increasing trend from \textbf{age:shapeCircle} term. we can conclude that for overall, subject performs better on box shape than circle shape.


\section{Conclusions}
In this report, we first do some numerical summaries and some exploratory plots, which give us a basic idea of the data and the relation between each varibles. We treat the trails as categorical variable and add one variables called "group" which split subject into young and old group by their age, then We use normal linear model to find the relationship between contact time and other variables on the data that collected by United States Naval Postgraduate School. we showed that age, sex, trails and shape all affect the contact time, and how they affect contact time, such as adult can do better than young and old people. The final model we get matches what we find in data exploration section. 

\section{Discussion}
In the future work, instead of adding one more variable to specify young and old people, we can separately do the normal linear regression for young and old people, that may give us a better result. Also from Figure 2, we notice the time and age are not linear related, so we can apply quartic model on this data, such as add $age^2$ term into our model.

\newpage
\appendix
\section{Appendix}
\subsection{R code}


\end{document}
